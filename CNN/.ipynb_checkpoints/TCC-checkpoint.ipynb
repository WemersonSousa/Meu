{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando feixes\n",
    "xtreino = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\BP\\\\Train_Beam.mat')\n",
    "xteste = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\BP\\\\Test_Beam.mat')\n",
    "#importando apontamento\n",
    "xteste_apontamento = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Apontamento.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando todas as linhas da matriz\n",
    "#1\n",
    "ytreino1 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_1.mat')\n",
    "yteste1 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_1.mat')\n",
    "#2\n",
    "ytreino2 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_2.mat')\n",
    "yteste2 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_2.mat')\n",
    "#3\n",
    "ytreino3 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_3.mat')\n",
    "yteste3 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_3.mat')\n",
    "#4\n",
    "ytreino4 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_4.mat')\n",
    "yteste4 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_4.mat')\n",
    "#5\n",
    "ytreino5 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_5.mat')\n",
    "yteste5 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_5.mat')\n",
    "#6\n",
    "ytreino6 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_6.mat')\n",
    "yteste6 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_6.mat')\n",
    "#7\n",
    "ytreino7 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_7.mat')\n",
    "yteste7 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_7.mat')\n",
    "#8\n",
    "ytreino8 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_8.mat')\n",
    "yteste8 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_8.mat')\n",
    "#9\n",
    "ytreino9 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_9.mat')\n",
    "yteste9 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_9.mat')\n",
    "#10\n",
    "ytreino10 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_10.mat')\n",
    "yteste10 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_10.mat')\n",
    "#11\n",
    "ytreino11 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Treino\\\\HOLO\\\\Train_holo_Linha_11.mat')\n",
    "yteste11 = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\Test_Holo_Linha_11.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtde = len(yteste1['Test_Holo_Linha_1'])\n",
    "y_test = np.zeros([qtde,11, 1])\n",
    "qtde_treino = len(ytreino1['Train_holo_Linha_1'])\n",
    "y_train = np.zeros([qtde_treino,11, 1])\n",
    "#1\n",
    "y_train[:,0] = ytreino1['Train_holo_Linha_1']\n",
    "y_test[:,0] = yteste1['Test_Holo_Linha_1']\n",
    "#2\n",
    "y_train[:,1] = ytreino2['Train_holo_Linha_2']\n",
    "y_test[:,1]  = yteste2['Test_Holo_Linha_2']\n",
    "#3\n",
    "y_train[:,2] = ytreino3['Train_holo_Linha_3']\n",
    "y_test[:,2] = yteste3['Test_Holo_Linha_3']\n",
    "#4\n",
    "y_train[:,3] = ytreino4['Train_holo_Linha_4']\n",
    "y_test[:,3] = yteste4['Test_Holo_Linha_4']\n",
    "#5\n",
    "y_train[:,4] = ytreino5['Train_holo_Linha_5']\n",
    "y_test[:,4] = yteste5['Test_Holo_Linha_5']\n",
    "#6\n",
    "y_train[:,5] = ytreino6['Train_holo_Linha_6']\n",
    "y_test[:,5] = yteste6['Test_Holo_Linha_6']\n",
    "#7\n",
    "y_train[:,6] = ytreino7['Train_holo_Linha_7']\n",
    "y_test[:,6] = yteste7['Test_Holo_Linha_7']\n",
    "#8\n",
    "y_train[:,7] = ytreino8['Train_holo_Linha_8']\n",
    "y_test[:,7] = yteste8['Test_Holo_Linha_8']\n",
    "#9\n",
    "y_train[:,8] = ytreino9['Train_holo_Linha_9']\n",
    "y_test[:,8] = yteste9['Test_Holo_Linha_9']\n",
    "#10\n",
    "y_train[:,9] = ytreino10['Train_holo_Linha_10']\n",
    "y_test[:,9] = yteste10['Test_Holo_Linha_10']\n",
    "#11\n",
    "y_train[:,10] = ytreino11['Train_holo_Linha_11']\n",
    "y_test[:,10] = yteste11['Test_Holo_Linha_11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(qtde,11,)\n",
    "y_train = y_train.reshape(qtde_treino,11,)\n",
    "\n",
    "y_test[:5,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8006"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64800"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qtde_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64800, 37, 37)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = xtreino['Train_Beam']\n",
    "x_test = xteste['Test_Beam']\n",
    "x_test_apontamento = xteste_apontamento['Test_Apontamento']\n",
    "pixelsx = 37\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel([y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(x_train, y_train[:,0], 10300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11770834, 0.11770834, 0.11770834, ..., 0.11770834, 0.11770834,\n",
       "        0.11770834],\n",
       "       [0.18519326, 0.18068698, 0.17507102, ..., 0.18677375, 0.18756657,\n",
       "        0.18519326],\n",
       "       [0.212157  , 0.18962309, 0.16741577, ..., 0.24689434, 0.23233061,\n",
       "        0.212157  ],\n",
       "       ...,\n",
       "       [0.212157  , 0.18962309, 0.16741577, ..., 0.24689434, 0.23233061,\n",
       "        0.212157  ],\n",
       "       [0.18519326, 0.18068698, 0.17507102, ..., 0.18677375, 0.18756657,\n",
       "        0.18519326],\n",
       "       [0.11770834, 0.11770834, 0.11770834, ..., 0.11770834, 0.11770834,\n",
       "        0.11770834]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[10300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 35, 35, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              296960    \n",
      "=================================================================\n",
      "Total params: 300,800\n",
      "Trainable params: 300,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model1.add(layers.MaxPooling2D())\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D())\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model1.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model1.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model1.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, pixelsx, pixelsx, 1)\n",
    "x_test = x_test.reshape(-1, pixelsx, pixelsx, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation dataset\n",
    "x_train_1, x_val_1, y_train_1, y_val_1 = train_test_split(x_train, y_train[:,0], test_size=0.2, random_state=42)\n",
    "x_train_2, x_val_2, y_train_2, y_val_2 = train_test_split(x_train, y_train[:,1], test_size=0.2, random_state=42)\n",
    "x_train_3, x_val_3, y_train_3, y_val_3 = train_test_split(x_train, y_train[:,2], test_size=0.2, random_state=42)\n",
    "x_train_4, x_val_4, y_train_4, y_val_4 = train_test_split(x_train, y_train[:,3], test_size=0.2, random_state=42)\n",
    "x_train_5, x_val_5, y_train_5, y_val_5 = train_test_split(x_train, y_train[:,4], test_size=0.2, random_state=42)\n",
    "x_train_6, x_val_6, y_train_6, y_val_6 = train_test_split(x_train, y_train[:,5], test_size=0.2, random_state=42)\n",
    "x_train_7, x_val_7, y_train_7, y_val_7 = train_test_split(x_train, y_train[:,6], test_size=0.2, random_state=42)\n",
    "x_train_8, x_val_8, y_train_8, y_val_8 = train_test_split(x_train, y_train[:,7], test_size=0.2, random_state=42)\n",
    "x_train_9, x_val_9, y_train_9, y_val_9 = train_test_split(x_train, y_train[:,8], test_size=0.2, random_state=42)\n",
    "x_train_10, x_val_10, y_train_10, y_val_10 = train_test_split(x_train, y_train[:,9], test_size=0.2, random_state=42)\n",
    "x_train_11, x_val_11, y_train_11, y_val_11 = train_test_split(x_train, y_train[:,10], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilando e Avaliando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 49s 28ms/step - loss: 3.8854 - accuracy: 0.1903 - val_loss: 2.1986 - val_accuracy: 0.4219\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 1.9445 - accuracy: 0.4600 - val_loss: 1.3928 - val_accuracy: 0.5995\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 1.2753 - accuracy: 0.6155 - val_loss: 1.0705 - val_accuracy: 0.6767\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 1.0100 - accuracy: 0.6925 - val_loss: 0.9107 - val_accuracy: 0.7199\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.8416 - accuracy: 0.7374 - val_loss: 0.8611 - val_accuracy: 0.7290\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 41s 26ms/step - loss: 0.7625 - accuracy: 0.7597 - val_loss: 0.8419 - val_accuracy: 0.7360\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.6966 - accuracy: 0.7770 - val_loss: 0.7043 - val_accuracy: 0.7778\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.6318 - accuracy: 0.7970 - val_loss: 0.6614 - val_accuracy: 0.7983\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 0.5895 - accuracy: 0.8084 - val_loss: 0.6171 - val_accuracy: 0.8138\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.5636 - accuracy: 0.8141 - val_loss: 0.6122 - val_accuracy: 0.8110\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.4678 - accuracy: 0.8511\n"
     ]
    }
   ],
   "source": [
    "# Compile The Model\n",
    "model1.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model1.fit(x_train_1, y_train_1, epochs=10, validation_data=(x_val_1, y_val_1))\n",
    "model1.evaluate(x_test,y_test[:,0])\n",
    "y_pred1 = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 35, 35, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              296960    \n",
      "=================================================================\n",
      "Total params: 300,800\n",
      "Trainable params: 300,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model2.add(layers.MaxPooling2D())\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D())\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model2.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model2.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model2.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 42s 25ms/step - loss: 3.4440 - accuracy: 0.2377 - val_loss: 1.5357 - val_accuracy: 0.5649\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 1.4094 - accuracy: 0.5823 - val_loss: 1.1698 - val_accuracy: 0.6555\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 1.0869 - accuracy: 0.6724 - val_loss: 1.0317 - val_accuracy: 0.6928\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.9186 - accuracy: 0.7212 - val_loss: 0.8554 - val_accuracy: 0.7401\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 45s 28ms/step - loss: 0.7950 - accuracy: 0.7535 - val_loss: 0.7439 - val_accuracy: 0.7741\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 46s 28ms/step - loss: 0.7150 - accuracy: 0.7781 - val_loss: 0.7105 - val_accuracy: 0.7792\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 48s 30ms/step - loss: 0.6472 - accuracy: 0.7941 - val_loss: 0.6534 - val_accuracy: 0.7971\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 46s 28ms/step - loss: 0.5945 - accuracy: 0.8113 - val_loss: 0.6742 - val_accuracy: 0.7910\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.5436 - accuracy: 0.8266 - val_loss: 0.5678 - val_accuracy: 0.8227\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 47s 29ms/step - loss: 0.5106 - accuracy: 0.8361 - val_loss: 0.5477 - val_accuracy: 0.8276\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.3878 - accuracy: 0.8629\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model2.fit(x_train_2, y_train_2, epochs=10, validation_data=(x_val_2, y_val_2))\n",
    "model2.evaluate(x_test,y_test[:,1])\n",
    "y_pred2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model3.add(layers.MaxPooling2D())\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D())\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model3.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model3.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model3.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model3.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 47s 29ms/step - loss: 3.3465 - accuracy: 0.2715 - val_loss: 1.3517 - val_accuracy: 0.5964\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 1.2097 - accuracy: 0.6430 - val_loss: 0.9291 - val_accuracy: 0.7183\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 48s 30ms/step - loss: 0.8976 - accuracy: 0.7227 - val_loss: 0.7979 - val_accuracy: 0.7559\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.7524 - accuracy: 0.7639 - val_loss: 0.6966 - val_accuracy: 0.7823\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.6535 - accuracy: 0.7894 - val_loss: 0.6278 - val_accuracy: 0.7990\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.5886 - accuracy: 0.8093 - val_loss: 0.5485 - val_accuracy: 0.8247\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.5369 - accuracy: 0.8244 - val_loss: 0.5363 - val_accuracy: 0.8275\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.4977 - accuracy: 0.8363 - val_loss: 0.5325 - val_accuracy: 0.8270\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.4679 - accuracy: 0.8448 - val_loss: 0.4886 - val_accuracy: 0.8415\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 41s 26ms/step - loss: 0.4293 - accuracy: 0.8585 - val_loss: 0.4487 - val_accuracy: 0.8543\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.3437 - accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model3.fit(x_train_3, y_train_3, epochs=10, validation_data=(x_val_3, y_val_3))\n",
    "model3.evaluate(x_test,y_test[:,2])\n",
    "y_pred3 = model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 35, 35, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              296960    \n",
      "=================================================================\n",
      "Total params: 300,800\n",
      "Trainable params: 300,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model4.add(layers.MaxPooling2D())\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D())\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model4.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model4.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model4.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model4.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 3.1004 - accuracy: 0.3122 - val_loss: 1.2366 - val_accuracy: 0.6219\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 1.1280 - accuracy: 0.6490 - val_loss: 0.9379 - val_accuracy: 0.7005\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 47s 29ms/step - loss: 0.8538 - accuracy: 0.7283 - val_loss: 0.7657 - val_accuracy: 0.7569\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.7360 - accuracy: 0.7621 - val_loss: 0.7061 - val_accuracy: 0.7735\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.6405 - accuracy: 0.7907 - val_loss: 0.6393 - val_accuracy: 0.7894\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.5885 - accuracy: 0.8075 - val_loss: 0.5773 - val_accuracy: 0.8136\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 40s 24ms/step - loss: 0.5350 - accuracy: 0.8232 - val_loss: 0.5422 - val_accuracy: 0.8148\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.5111 - accuracy: 0.8295 - val_loss: 0.5053 - val_accuracy: 0.8328\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 39s 24ms/step - loss: 0.4761 - accuracy: 0.8397 - val_loss: 0.4620 - val_accuracy: 0.8503\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 52s 32ms/step - loss: 0.4530 - accuracy: 0.8447 - val_loss: 0.4218 - val_accuracy: 0.8643\n",
      "251/251 [==============================] - 6s 20ms/step - loss: 0.3620 - accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "model4.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model4.fit(x_train_4, y_train_4, epochs=10, validation_data=(x_val_4, y_val_4))\n",
    "model4.evaluate(x_test,y_test[:,3])\n",
    "y_pred4 = model4.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model5.add(layers.MaxPooling2D())\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D())\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model5.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model5.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model5.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model5.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 41s 24ms/step - loss: 2.7648 - accuracy: 0.3596 - val_loss: 1.1265 - val_accuracy: 0.6343\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 38s 24ms/step - loss: 1.0166 - accuracy: 0.6731 - val_loss: 0.8210 - val_accuracy: 0.7329\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 38s 24ms/step - loss: 0.7733 - accuracy: 0.7423 - val_loss: 0.7119 - val_accuracy: 0.7580\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.6645 - accuracy: 0.7741 - val_loss: 0.6202 - val_accuracy: 0.7918\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 48s 29ms/step - loss: 0.6049 - accuracy: 0.7909 - val_loss: 0.6125 - val_accuracy: 0.7947\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 0.5650 - accuracy: 0.8008 - val_loss: 0.5905 - val_accuracy: 0.7935\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.5269 - accuracy: 0.8159 - val_loss: 0.5157 - val_accuracy: 0.8209\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.5075 - accuracy: 0.8225 - val_loss: 0.5293 - val_accuracy: 0.8182\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.4760 - accuracy: 0.8329 - val_loss: 0.4870 - val_accuracy: 0.8325\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 47s 29ms/step - loss: 0.4509 - accuracy: 0.8393 - val_loss: 0.4556 - val_accuracy: 0.8400\n",
      "251/251 [==============================] - 3s 11ms/step - loss: 0.3782 - accuracy: 0.8681\n"
     ]
    }
   ],
   "source": [
    "model5.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model5.fit(x_train_5, y_train_5, epochs=10, validation_data=(x_val_5, y_val_5))\n",
    "model5.evaluate(x_test,y_test[:,4])\n",
    "y_pred5 = model5.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 35, 35, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              296960    \n",
      "=================================================================\n",
      "Total params: 300,800\n",
      "Trainable params: 300,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model6.add(layers.MaxPooling2D())\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model6.add(layers.MaxPooling2D())\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model6.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model6.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model6.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model6.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 47s 28ms/step - loss: 2.1614 - accuracy: 0.4558 - val_loss: 0.8295 - val_accuracy: 0.7025\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.7677 - accuracy: 0.7176 - val_loss: 0.6102 - val_accuracy: 0.7736\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.5990 - accuracy: 0.7765 - val_loss: 0.5165 - val_accuracy: 0.8046\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.5134 - accuracy: 0.8088 - val_loss: 0.4758 - val_accuracy: 0.8216\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 45s 28ms/step - loss: 0.4703 - accuracy: 0.8224 - val_loss: 0.4663 - val_accuracy: 0.8225\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.4235 - accuracy: 0.8395 - val_loss: 0.3764 - val_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 45s 28ms/step - loss: 0.4121 - accuracy: 0.8446 - val_loss: 0.3884 - val_accuracy: 0.8485\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 45s 28ms/step - loss: 0.3769 - accuracy: 0.8583 - val_loss: 0.3202 - val_accuracy: 0.8859\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 49s 30ms/step - loss: 0.3621 - accuracy: 0.8644 - val_loss: 0.3835 - val_accuracy: 0.8596\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 47s 29ms/step - loss: 0.3418 - accuracy: 0.8728 - val_loss: 0.3594 - val_accuracy: 0.8626\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.3255 - accuracy: 0.8763\n"
     ]
    }
   ],
   "source": [
    "model6.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model6.fit(x_train_6, y_train_6, epochs=10, validation_data=(x_val_6, y_val_6))\n",
    "model6.evaluate(x_test,y_test[:,5])\n",
    "y_pred6 = model6.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model7.add(layers.MaxPooling2D())\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D())\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model7.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model7.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model7.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 2.9186 - accuracy: 0.3455 - val_loss: 0.9591 - val_accuracy: 0.6880\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.8390 - accuracy: 0.7236 - val_loss: 0.6888 - val_accuracy: 0.7658\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.6067 - accuracy: 0.7900 - val_loss: 0.5415 - val_accuracy: 0.8186\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.5185 - accuracy: 0.8193 - val_loss: 0.5174 - val_accuracy: 0.8215\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.4516 - accuracy: 0.8415 - val_loss: 0.4377 - val_accuracy: 0.8473\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.4220 - accuracy: 0.8508 - val_loss: 0.4246 - val_accuracy: 0.8523\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.3861 - accuracy: 0.8653 - val_loss: 0.3854 - val_accuracy: 0.8653\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 48s 30ms/step - loss: 0.3568 - accuracy: 0.8740 - val_loss: 0.3586 - val_accuracy: 0.8791\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.3354 - accuracy: 0.8813 - val_loss: 0.3411 - val_accuracy: 0.8832\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 46s 29ms/step - loss: 0.3173 - accuracy: 0.8866 - val_loss: 0.3500 - val_accuracy: 0.8837\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.2776 - accuracy: 0.9031\n"
     ]
    }
   ],
   "source": [
    "model7.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model7.fit(x_train_7, y_train_7, epochs=10, validation_data=(x_val_7, y_val_7))\n",
    "model7.evaluate(x_test,y_test[:,6])\n",
    "y_pred7 = model7.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 35, 35, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2048)              296960    \n",
      "=================================================================\n",
      "Total params: 300,800\n",
      "Trainable params: 300,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model8 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model8.add(layers.MaxPooling2D())\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model8.add(layers.MaxPooling2D())\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model8.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model8.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model8.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model8.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 3.1333 - accuracy: 0.3171 - val_loss: 1.2520 - val_accuracy: 0.6265\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 1.1439 - accuracy: 0.6481 - val_loss: 0.9896 - val_accuracy: 0.6917\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.9194 - accuracy: 0.7047 - val_loss: 0.8615 - val_accuracy: 0.7262\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 41s 26ms/step - loss: 0.7846 - accuracy: 0.7446 - val_loss: 0.7600 - val_accuracy: 0.7480\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.7004 - accuracy: 0.7683 - val_loss: 0.6737 - val_accuracy: 0.7838\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.6361 - accuracy: 0.7877 - val_loss: 0.6045 - val_accuracy: 0.7998\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.5795 - accuracy: 0.8070 - val_loss: 0.6238 - val_accuracy: 0.7898\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.5453 - accuracy: 0.8170 - val_loss: 0.5316 - val_accuracy: 0.8262\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.5050 - accuracy: 0.8300 - val_loss: 0.5180 - val_accuracy: 0.8283\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.4860 - accuracy: 0.8388 - val_loss: 0.4722 - val_accuracy: 0.8438\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.3986 - accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "model8.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model8.fit(x_train_8, y_train_8, epochs=10, validation_data=(x_val_8, y_val_8))\n",
    "model8.evaluate(x_test,y_test[:,7])\n",
    "y_pred8 = model8.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model9.add(layers.MaxPooling2D())\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model9.add(layers.MaxPooling2D())\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model9.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model9.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model9.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model9.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 3.3783 - accuracy: 0.2673 - val_loss: 1.1325 - val_accuracy: 0.6609\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.9944 - accuracy: 0.6934 - val_loss: 0.7670 - val_accuracy: 0.7518\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.7420 - accuracy: 0.7565 - val_loss: 0.6442 - val_accuracy: 0.7948\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 41s 26ms/step - loss: 0.6078 - accuracy: 0.7998 - val_loss: 0.5512 - val_accuracy: 0.8233\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.5358 - accuracy: 0.8230 - val_loss: 0.4900 - val_accuracy: 0.8464\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.4737 - accuracy: 0.8403 - val_loss: 0.4619 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.4505 - accuracy: 0.8509 - val_loss: 0.4237 - val_accuracy: 0.8639\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.4038 - accuracy: 0.8665 - val_loss: 0.4697 - val_accuracy: 0.8508\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.3797 - accuracy: 0.8736 - val_loss: 0.3819 - val_accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.3492 - accuracy: 0.8827 - val_loss: 0.3601 - val_accuracy: 0.8819\n",
      "251/251 [==============================] - 3s 10ms/step - loss: 0.2925 - accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "model9.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model9.fit(x_train_9, y_train_9, epochs=10, validation_data=(x_val_9, y_val_9))\n",
    "model9.evaluate(x_test,y_test[:,8])\n",
    "y_pred9 = model9.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_63 (Conv2D)           (None, 35, 35, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 7, 7, 16)          272       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2048)              296960    \n",
      "=================================================================\n",
      "Total params: 300,800\n",
      "Trainable params: 300,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model10 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model10.add(layers.MaxPooling2D())\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model10.add(layers.MaxPooling2D())\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model10.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model10.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model10.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model10.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "model10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 3.6924 - accuracy: 0.2050 - val_loss: 1.9658 - val_accuracy: 0.4457\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 1.7728 - accuracy: 0.4913 - val_loss: 1.4049 - val_accuracy: 0.5910\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 1.2990 - accuracy: 0.6092 - val_loss: 1.1256 - val_accuracy: 0.6581\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 40s 24ms/step - loss: 1.0545 - accuracy: 0.6782 - val_loss: 0.9477 - val_accuracy: 0.7046\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 0.9056 - accuracy: 0.7192 - val_loss: 0.8322 - val_accuracy: 0.7408\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.8284 - accuracy: 0.7381 - val_loss: 0.7624 - val_accuracy: 0.7572\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 0.7559 - accuracy: 0.7610 - val_loss: 0.7445 - val_accuracy: 0.7599\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.6911 - accuracy: 0.7809 - val_loss: 0.6530 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 0.6299 - accuracy: 0.7954 - val_loss: 0.6191 - val_accuracy: 0.8039\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 44s 27ms/step - loss: 0.6045 - accuracy: 0.8037 - val_loss: 0.6013 - val_accuracy: 0.8061\n",
      "251/251 [==============================] - 2s 9ms/step - loss: 0.4836 - accuracy: 0.8340\n"
     ]
    }
   ],
   "source": [
    "model10.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model10.fit(x_train_10, y_train_10, epochs=10, validation_data=(x_val_10, y_val_10))\n",
    "model10.evaluate(x_test,y_test[:,9])\n",
    "y_pred10 = model10.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11 = models.Sequential()\n",
    "# Feature Extraction Section (The Convolution and The Pooling Layer)\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(pixelsx, pixelsx, 1)))\n",
    "model11.add(layers.MaxPooling2D())\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model11.add(layers.MaxPooling2D())\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "model11.add(layers.Conv2D(filters=16, kernel_size=(1, 1), activation='relu'))\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model11.add(layers.MaxPooling2D())\n",
    "#model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "# Reshape the image into one-dimensional vector\n",
    "model11.add(layers.Flatten())\n",
    "# Classification Section (The Fully Connected Layer)\n",
    "#model.add(layers.Dense(120, activation='relu'))\n",
    "#model.add(layers.Dense(84, activation='relu'))\n",
    "model11.add(layers.Dense(2048, activation='softmax'))\n",
    "# Show summary of the model\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1620/1620 [==============================] - 43s 26ms/step - loss: 3.8551 - accuracy: 0.2093 - val_loss: 2.2251 - val_accuracy: 0.4053\n",
      "Epoch 2/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 1.9825 - accuracy: 0.4578 - val_loss: 1.4877 - val_accuracy: 0.5766\n",
      "Epoch 3/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 1.3603 - accuracy: 0.6055 - val_loss: 1.1272 - val_accuracy: 0.6791\n",
      "Epoch 4/10\n",
      "1620/1620 [==============================] - 40s 25ms/step - loss: 1.0427 - accuracy: 0.6898 - val_loss: 0.9844 - val_accuracy: 0.7117\n",
      "Epoch 5/10\n",
      "1620/1620 [==============================] - 43s 27ms/step - loss: 0.8991 - accuracy: 0.7270 - val_loss: 0.8371 - val_accuracy: 0.7552\n",
      "Epoch 6/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.7880 - accuracy: 0.7560 - val_loss: 0.7619 - val_accuracy: 0.7721\n",
      "Epoch 7/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.7113 - accuracy: 0.7776 - val_loss: 0.7193 - val_accuracy: 0.7839\n",
      "Epoch 8/10\n",
      "1620/1620 [==============================] - 41s 26ms/step - loss: 0.6574 - accuracy: 0.7961 - val_loss: 0.6543 - val_accuracy: 0.8046\n",
      "Epoch 9/10\n",
      "1620/1620 [==============================] - 42s 26ms/step - loss: 0.5813 - accuracy: 0.8143 - val_loss: 0.6122 - val_accuracy: 0.8150\n",
      "Epoch 10/10\n",
      "1620/1620 [==============================] - 41s 25ms/step - loss: 0.5567 - accuracy: 0.8211 - val_loss: 0.6088 - val_accuracy: 0.8141\n",
      "251/251 [==============================] - 3s 9ms/step - loss: 0.4910 - accuracy: 0.8399\n"
     ]
    }
   ],
   "source": [
    "model11.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "# Fit And Evaluate The Model Using Validation Dataset\n",
    "model11.fit(x_train_11, y_train_11, epochs=10, validation_data=(x_val_11, y_val_11))\n",
    "model11.evaluate(x_test,y_test[:,10])\n",
    "y_pred11 = model11.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1029.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted = np.zeros([qtde,11])\n",
    "y_predicted[:,0] = [np.argmax(element) for element in y_pred1]\n",
    "y_predicted[:,1] = [np.argmax(element) for element in y_pred2]\n",
    "y_predicted[:,2] = [np.argmax(element) for element in y_pred3]\n",
    "y_predicted[:,3] = [np.argmax(element) for element in y_pred4]\n",
    "y_predicted[:,4] = [np.argmax(element) for element in y_pred5]\n",
    "y_predicted[:,5] = [np.argmax(element) for element in y_pred6]\n",
    "y_predicted[:,6] = [np.argmax(element) for element in y_pred7]\n",
    "y_predicted[:,7] = [np.argmax(element) for element in y_pred8]\n",
    "y_predicted[:,8] = [np.argmax(element) for element in y_pred9]\n",
    "y_predicted[:,9] = [np.argmax(element) for element in y_pred10]\n",
    "y_predicted[:,10] = [np.argmax(element) for element in y_pred11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportando Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model1\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model2\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model3\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model4\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model5\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model6\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model7\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model8\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model9\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model10\\assets\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\wemer\\Desktop\\tcc\\Arquivos\\Models\\Ant11\\Model11\\assets\n"
     ]
    }
   ],
   "source": [
    "model1.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model1')\n",
    "model2.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model2')\n",
    "model3.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model3')\n",
    "model4.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model4')\n",
    "model5.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model5')\n",
    "model6.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model6')\n",
    "model7.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model7')\n",
    "model8.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model8')\n",
    "model9.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model9')\n",
    "model10.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model10')\n",
    "model11.save('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes nicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import csv\n",
    "import pandas\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lendo redes neurais modo normal\n",
    "model1 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model1')\n",
    "model2 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model2')\n",
    "model3 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model3')\n",
    "model4 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model4')\n",
    "model5 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model5')\n",
    "model6 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model6')\n",
    "model7 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model7')\n",
    "model8 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model8')\n",
    "model9 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model9')\n",
    "model10 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model10')\n",
    "model11 = keras.models.load_model('C:\\\\Users\\\\wemer\\\\Desktop\\\\tcc\\\\Arquivos\\\\Models\\\\Ant11\\\\Model11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2_binrow(y):\n",
    "    b =  [int(i) for i in list('{0:0b}'.format(y))]\n",
    "    c = np.asarray(b)\n",
    "    d = np.pad(c, (11-len(c), 0), 'constant')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linhas_cnn(X):\n",
    "    X = X.reshape(-1, pixelsx, pixelsx, 1)\n",
    "    y_pred = np.zeros([1,11])\n",
    "    y_pred[:,0] = [np.argmax(element) for element in model1.predict(X)]\n",
    "    y_pred[:,1] = [np.argmax(element) for element in model2.predict(X)]\n",
    "    y_pred[:,2] = [np.argmax(element) for element in model3.predict(X)]\n",
    "    y_pred[:,3] = [np.argmax(element) for element in model4.predict(X)]\n",
    "    y_pred[:,4] = [np.argmax(element) for element in model5.predict(X)]\n",
    "    y_pred[:,5] = [np.argmax(element) for element in model6.predict(X)]\n",
    "    y_pred[:,6] = [np.argmax(element) for element in model7.predict(X)]\n",
    "    y_pred[:,7] = [np.argmax(element) for element in model8.predict(X)]\n",
    "    y_pred[:,8] = [np.argmax(element) for element in model9.predict(X)]\n",
    "    y_pred[:,9] = [np.argmax(element) for element in model10.predict(X)]\n",
    "    y_pred[:,10] = [np.argmax(element) for element in model11.predict(X)]\n",
    "    return y_pred;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convbin(Y):\n",
    "    y_bin = np.zeros([11,11])\n",
    "    for k in range(0,11):\n",
    "        y_bin[:,k] = conv2_binrow(int(Y[k]))\n",
    "    return y_bin;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando feixe\n",
    "x_opt_teste = scipy.io.loadmat('C:\\\\Users\\\\wemer\\\\Documents\\\\MATLAB\\\\Dataset\\\\Hologramas\\\\Teste\\\\HOLO\\\\opt_test.mat')\n",
    "x_opt_test = x_opt_teste['opt_test']\n",
    "pixelsx = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = linhas_cnn(x_opt_test)\n",
    "c = np.flipud(convbin(a[0]))\n",
    "scipy.io.savemat('./Arquivos/Testes_Feixes/opt_test.mat', dict(x=2,y=c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
